{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from ecgdetectors import Detectors\n",
    "from petastorm import make_reader\n",
    "from sklearn.metrics import auc,roc_curve,precision_recall_curve,roc_auc_score,RocCurveDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import (RepeatedStratifiedKFold, cross_val_score,\n",
    "                                     train_test_split)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "import shared_utils.utils_data as utils_data\n",
    "from shared_utils import Logistic_reg_model\n",
    "\n",
    "\n",
    "path_formatted_glasgow = \"/workspaces/maitrise/data/20221006_physio_quality/set-a/dataParquet\"\n",
    "path_petastorm = f\"file:///{path_formatted_glasgow}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/workspaces/ecg_evaluation/results\"\n",
    "name_method = [\"Corr_interlead\",\"Corr_intralead\",\"wPMF\",\"SNRECG\",\"HR\",\"Kurtosis\",\"Flatline\",\"TSD\"]\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "os.path.join(save_path,\"\")\n",
    "if not \"quality_metrics.nc\" in os.listdir(save_path):\n",
    "    print(\"Computing metrics\")\n",
    "    if not \"ecg_data.nc\" in os.listdir(save_path):\n",
    "        ds_data = utils_data.format_data_to_xarray(path_petastorm, save_path)\n",
    "    else:\n",
    "        ds_data = xr.load_dataset(os.path.join(save_path,\"ecg_data.nc\"))\n",
    "\n",
    "    ds_metrics = save_metrics_to_xarray(ds_data, name_method, save_path, verbose = True)\n",
    "else:\n",
    "    ds_metrics = xr.load_dataset(os.path.join(save_path,\"quality_metrics.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Save summary table into a folder \n",
    "def save_table(path_data,summary,name_folder):\n",
    "    tab1 = \"Results_logit\"\n",
    "    tab2 = \"Coefficient_results\"\n",
    "    path_to_folder = os.path.join(path_data,name_folder)\n",
    "    if not os.path.exists(path_to_folder):\n",
    "        os.mkdir(path_to_folder)\n",
    "    plt.rc('figure', figsize=(12, 7))\n",
    "    #plt.text(0.01, 0.05, str(model.summary()), {'fontsize': 12}) old approach\n",
    "    plt.text(0.01, 0.05, str(summary), {'fontsize': 17}, fontproperties = 'monospace') # approach improved by OP -> monospace!\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(path_to_folder,'output.png'))\n",
    "    for i,t in zip(range(0,2),[tab1,tab2]):\n",
    "        summary.tables[i].to_csv(os.path.join(path_to_folder,t+\".csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_filtered = ds_metrics.where(ds_metrics.data_quality != \"unlabeled\").dropna(dim = \"id\")\n",
    "\n",
    "np_metrics = ds_filtered.quality_metrics.values\n",
    "metrics_names = ds_filtered.metric_name.values.tolist()\n",
    "np_label = ds_filtered.data_quality.values\n",
    "##Opposite labelling : instead of labelling 1 as acceptable, we label 1 as unacceptable : \n",
    "opposite = True\n",
    "reverseUNO_y = np_label.copy()\n",
    "original_label = np_label.copy()\n",
    "reverseUNO_y[np_label == \"acceptable\" ] = 0\n",
    "reverseUNO_y[np_label == \"unacceptable\" ] = 1\n",
    "reverseUNO_y = reverseUNO_y.astype(int)\n",
    "original_label[np_label == \"acceptable\" ] = 1\n",
    "original_label[np_label == \"unacceptable\" ] = 0\n",
    "original_label = original_label.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_index = metrics_names.index(\"HR\")\n",
    "HR_metrics = np_metrics[:,:,HR_index].min(axis=1)\n",
    "X = np_metrics.mean(axis = 1)\n",
    "X[:,HR_index] = HR_metrics\n",
    "df_X = pd.DataFrame(X, columns =metrics_names )\n",
    "df_y_normal = pd.DataFrame(original_label, columns = [\"y\"])\n",
    "df_y_reverse = pd.DataFrame(reverseUNO_y, columns = [\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.3, random_state=0)\n",
    "columns = X_train.columns\n",
    "\n",
    "os_data_X,os_data_y=smote.fit_resample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\n",
    "# we can Check the numbers of our data\n",
    "print(\"length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of no subscription in oversampled data\",len(os_data_y[os_data_y['y']==0]))\n",
    "print(\"Number of subscription\",len(os_data_y[os_data_y['y']==1]))\n",
    "print(\"Proportion of no subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==0])/len(os_data_X))\n",
    "print(\"Proportion of subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Check Backward modele selection on SMOTE and Non SMOTE dataset :\n",
    "SMOTE_feature = Logistic_reg_model.Backward_model_selection(os_data_X,os_data_y)\n",
    "print(SMOTE_feature)\n",
    "\n",
    "Normal_feature = Logistic_reg_model.Backward_model_selection(df_X,df_y_normal)\n",
    "print(Normal_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##What we found using JMI : \n",
    "Logistic_reg_model.JMI_calculator(df_X,df_y_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###We will fit a Logistic model on the \"SMOTED\" train dataset\n",
    "\n",
    "HR_index = list(os_data_X.columns.values).index(\"HR\")\n",
    "\n",
    "\n",
    "logit_model=sm.Logit(os_data_y,os_data_X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "#save_table(save_path,result.summary2(),\"all_features_SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Check impact of TSD:\n",
    "cols = ['Corr_interlead', 'wPMF', 'HR', 'TSD']\n",
    "logit_model=sm.Logit(os_data_y,os_data_X[cols])\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(save_path,result.summary2(),\"Backward_model_selection_features_SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without TSD :\n",
    "cols.remove(\"TSD\")\n",
    "logit_model=sm.Logit(os_data_y,os_data_X[cols])\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(save_path,result.summary2(),\"Backward_model_selection_features_SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Without taking into account class imbalanced : \n",
    "logit_model = sm.Logit(df_y_normal,df_X[cols])\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(save_path,result.summary2(),\"all_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Corr_interlead', 'HR', 'SNRECG', 'TSD']\n",
    "logit_model=sm.Logit(df_y_normal,df_X[cols])\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(save_path,result.summary2(),\"Backward_model_selection_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.remove(\"TSD\")\n",
    "logit_model=sm.Logit(df_y_normal,df_X[cols])\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(save_path,result.summary2(),\"rm_TSD_features_SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Corr_interlead', 'Corr_intralead', 'wPMF', 'SNRECG', 'HR']\n",
    "logit_model=sm.Logit(df_y_normal,df_X[cols])\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "save_table(save_path,result.summary2(),\"L2_reg_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Feature selection : selectKbest with mutula_info_classif\n",
    "bestfeatures = SelectKBest(score_func = mutual_info_classif,k=8)\n",
    "fit = bestfeatures.fit(df_X,df_y_normal.values.ravel())\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(df_X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(len(metrics_names),'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_imb = ExtraTreesClassifier()\n",
    "cols = df_X.columns.values\n",
    "print(cols)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y_normal.values.ravel(), test_size=0.3, random_state=0)\n",
    "model_imb.fit(X_train,y_train.ravel())\n",
    "print(model_imb.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model_imb.feature_importances_, index=df_X.columns)\n",
    "#feat_importances.reindex(cols)\n",
    "print(feat_importances)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.title(\"ExtraTreesClassifier for features selection fitted on original training dataset (score : GINI)\")\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols = ['wPMF', 'SNRECG',\"HR\"]\n",
    "Logistic_reg_model.ExtraTreeClassifier_CV_Feature_selection(df_X,df_y_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_reg_model.Kbest_MutulaInformation_CV(df_X,df_y_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y_normal.values.ravel(), test_size=0.3, random_state=0)\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "os_data_X,os_data_y=smote.fit_resample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns)\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(os_data_X,os_data_y.values.ravel())\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=os_data_X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.title(\"ExtraTreesClassifier results for features selection, fitted on SMOTED training dataset\")\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = df_X.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,20))\n",
    "#plot heat map\n",
    "g=sn.heatmap(df_X[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Final trial : Do feature selection by using regularization : L1 and L2 (we will only do this on the original dataset)\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "X_train, X_test, y_train, y_test_= train_test_split(df_X, df_y_normal.values.ravel(), test_size=0.3, random_state=0)\n",
    "columns = X_train.columns\n",
    "HRindex = list(X_train.columns).index(\"HR\")\n",
    "os_data_X = pd.DataFrame(data=X_train,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=y_train,columns=['y'])\n",
    "sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l2'))\n",
    "\n",
    "sel_.fit(os_data_X,os_data_y)\n",
    "\n",
    "selected_feat =os_data_X.columns[(sel_.get_support())]\n",
    "print(selected_feat)\n",
    "print('total features: {}'.format((os_data_X.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "      np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###We create logistic regression model based on what was found by each feature selection model\n",
    "\n",
    "##Using our Backward model selection feature : \n",
    "Logistic_reg_model.ROC_PR_CV_curve_model(df_X,df_y_normal,cols = [\"TSD\",\"Corr_interlead\",\"HR\",\"SNRECG\"],k_cv = 10,pos_label = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "Logistic_reg_model.save_model_LR(df_X,df_y_normal,cols = [\"TSD\",\"Corr_interlead\",\"HR\",\"SNRECG\"],opp  =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_reg_model.Classification_report_model(df_X,df_y_normal,cols = [\"Corr_interlead\",\"HR\",\"SNRECG\",\"TSD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "Logistic_reg_model.ROC_PR_CV_curve_model(df_X,df_y_normal,cols = [\"Corr_interlead\",\"HR\",\"SNRECG\"],k_cv = 10,opp = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_reg_model.Classification_report_model(df_X,df_y_normal,cols = [\"Corr_interlead\",\"HR\",\"SNRECG\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_reg_model.save_model_LR(df_X,df_y_normal,cols = [\"Corr_interlead\",\"HR\",\"SNRECG\"],opp  =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_reg_model.save_model_LR(df_X,df_y_normal,cols = [\"Corr_interlead\",\"HR\",\"SNRECG\",\"Corr_intralead\"],opp  =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_reg_model.Classification_report_model(df_X,df_y_normal,cols = [\"Corr_interlead\",\"HR\",\"SNRECG\",\"Corr_intralead\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_reg_model.ROC_PR_CV_curve_model(df_X,df_y_normal,cols = [\"Corr_interlead\",\"HR\",\"SNRECG\",\"Corr_intralead\"],k_cv = 10,opp = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "Logistic_reg_model.ROC_PR_CV_curve_model(df_X,df_y_normal,cols = ['Corr_interlead', 'Corr_intralead', 'wPMF', 'SNRECG', 'HR'],k_cv = 10,opp = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_reg_model.ROC_PR_CV_curve_model(df_X,df_y_reverse,cols = [\"wPMF\"],k_cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Using estimator from SMOTE:\n",
    "Logistic_reg_model.Classification_report_model(df_X,df_y_normal,cols = [\"wPMF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_reg_model.Classification_report_model(df_X,df_y_normal,cols = [\"TSD\",\"Corr_interlead\",\"HR\",\"SNRECG\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_reg_model.Classification_report_model(df_X,df_y_normal,cols = [\"wPMF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_reg_model.old_threshold_calculator(df_X,df_y_normal,cols = [\"TSD\",\"Corr_interlead\",\"HR\",\"SNRECG\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_g = [[\"TSD\",\"Corr_interlead\",\"HR\",\"SNRECG\"],[\"Corr_interlead\",\"HR\",\"SNRECG\",\"Corr_intralead\"],['Corr_interlead', 'Corr_intralead', 'wPMF', 'SNRECG', 'HR']]\n",
    "name_model = [\"Backward selection\",\"JMI/MI\",\"L2 Reg\"]\n",
    "Logistic_reg_model.Global_comp_ROC_PR_mean_curve(df_X,df_y_normal,cols_g,name_model,pos_label=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "1e9b5c13aa136530306b9d0fda952fcd75969540fafdedb30f13be0697230024"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
