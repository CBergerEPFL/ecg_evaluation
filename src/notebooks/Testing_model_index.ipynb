{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using mit-bih-noise-stress-test-database, Test our models and index performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from petastorm import make_reader\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import os\n",
    "import sys\n",
    "import xarray as xr\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "from operations.dataset_manager import get_path_petastorm_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set matplotlib window size and parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 32})\n",
    "plt.rcParams[\"legend.fontsize\"] = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_save_path = \"/workspaces/ecg_evaluation/results\"\n",
    "data_save_path = get_path_petastorm_format(\"mit-bih-noise-stress-test-database-1.0.0\",\"ParquetFile\")\n",
    "save_path  = \"/workspaces/ecg_evaluation/results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with make_reader(data_save_path) as reader:\n",
    "    for row in reader:\n",
    "        data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get save files (where model is saved)\n",
    "\n",
    "model_name = [\n",
    "                f.split(\".\")[0]\n",
    "                for f in os.listdir(models_save_path)\n",
    "                if os.path.isfile(os.path.join(models_save_path,f )) and (f.endswith(\".sav\"))\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_index = [\n",
    "        \"Corr_interlead\",\n",
    "        \"Corr_intralead\",\n",
    "        \"wPMF\",\n",
    "        \"SNRECG\",\n",
    "        \"HR\",\n",
    "        \"Flatline\",\n",
    "        \"TSD\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model on new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide into the 3 noises present in the dataset (em,ma,bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (save_path is not None) and (not os.path.exists(save_path)):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "if \"file://\" not in data_save_path:\n",
    "   path_petastorm = f\"file:///{data_save_path}\"\n",
    "else:\n",
    "   path_petastorm = data_save_path\n",
    "\n",
    "\n",
    "array_signal = []\n",
    "array_name = []\n",
    "array_fs = []\n",
    "array_signal_name = []\n",
    "array_units = []\n",
    "array_nb_sig = []\n",
    "array_nb_time_window = []\n",
    "with make_reader(data_save_path) as reader:\n",
    "    for sample in reader:\n",
    "        if len(sample.signal[0,0,:]) != 5000:\n",
    "            continue\n",
    "\n",
    "        array_signal.append(sample.signal.reshape((sample.nb_time_window*sample.n_sig,sample.sig_len)))\n",
    "        array_name.append(sample.noun_id.decode(\"utf-8\"))\n",
    "        array_fs.append(sample.fs)\n",
    "        array_signal_name.append([sample.sig_name[j].decode(\"utf-8\") for j in range(len(sample.sig_name))])\n",
    "        array_units.append([sample.units[j].decode(\"utf-8\") for j in range(len(sample.units))])\n",
    "        array_nb_sig.append(sample.n_sig)\n",
    "        array_nb_time_window.append(sample.nb_time_window)\n",
    "\n",
    "ds_ecg = xr.Dataset(\n",
    "        data_vars=dict(\n",
    "            signal=([\"id\", \"n_sig*nb_time_window\", \"time\"], np.array(array_signal)),\n",
    "            fs=([\"id\"], np.array(array_fs)),\n",
    "            signal_names=([\"id\",\"signal_names\"], np.array(array_signal_name)),\n",
    "            units = ([\"id\",\"units\"],np.array(array_units)),\n",
    "            n_time_window = ([\"id\"],np.array(array_nb_time_window)),\n",
    "            n_sig=([\"id\"], np.array(array_nb_sig))\n",
    "        ),\n",
    "        coords=dict(\n",
    "            id=([\"id\"], np.array(array_name)),\n",
    "            time=([\"time\"], np.arange(0, 5000)),\n",
    "\n",
    "        ),\n",
    "        attrs=dict(description=\"ecg with real noise data\")\n",
    "    )\n",
    "\n",
    "if save_path is not None:\n",
    "    ds_ecg.to_netcdf(os.path.join(save_path, \"ecg_data_mit_bih_noise_test.nc\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_ecg.signal.values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test each model performance for each noise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
