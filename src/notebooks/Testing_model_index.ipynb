{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using mit-bih-noise-stress-test-database, Test our models and index performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "import os\n",
    "import itertools\n",
    "import sys\n",
    "import xarray as xr\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "from operations.dataset_manager import get_path_petastorm_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 32})\n",
    "plt.rcParams[\"legend.fontsize\"] = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = xr.load_dataset(\"/workspaces/ecg_evaluation/results/quality_metrics.nc\")\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_save_path = \"/workspaces/ecg_evaluation/results\"\n",
    "data_save_path = get_path_petastorm_format(\"mit-bih-noise-stress-test-database-1.0.0\",\"ParquetFile\")\n",
    "save_path  = \"/workspaces/ecg_evaluation/results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get save files (where model is saved)\n",
    "\n",
    "model_name = [\n",
    "                f.split(\".\")[0]\n",
    "                for f in os.listdir(models_save_path)\n",
    "                if os.path.isfile(os.path.join(models_save_path,f )) and (f.endswith(\".sav\"))\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_index = [\n",
    "        \"Corr_interlead\",\n",
    "        \"Corr_intralead\",\n",
    "        \"wPMF\",\n",
    "        \"SNRECG\",\n",
    "        \"HR\",\n",
    "        \"Flatline\",\n",
    "        \"TSD\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model on new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please note that you will have to get your dataset ready and your metrics already calculated using the command describe on the git repo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_path = \"/workspaces/ecg_evaluation/results/mit_bih_noise_test_metrics.nc\"\n",
    "metrics = xr.load_dataset(data_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check data metrics \n",
    "id_signals = metrics.id.values\n",
    "values_metrics = metrics.quality_metrics.values\n",
    "metrics_name = metrics.metric_name.values\n",
    "signal = metrics.signal.values\n",
    "nb_segment = metrics.number_signal.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test each model performance for each noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will specifically focus on the noises signal. So, let's isolate them :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_noise_new = [\"em\",\"ma\",\"bw\"]\n",
    "list_noise_old = [\"oldem\",\"oldma\",\"oldbw\"]\n",
    "index_noise_new = [np.where(id_signals==n)[0][0] for n in list_noise_new]\n",
    "index_noise_old = [np.where(id_signals==n)[0][0] for n in list_noise_old]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3 type of noise. We will reunite the old and new version\n",
    "noise_data = np.zeros([len(list_noise_new),nb_segment*2,values_metrics.shape[-1]])\n",
    "\n",
    "for j in range(noise_data.shape[0]):\n",
    "    noise_data[j,:,:] = np.concatenate((values_metrics[index_noise_new[j],:,:],values_metrics[index_noise_old[j],:,:]),axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Small check concerning the values performance for each noise.\n",
    "palette = itertools.cycle(sns.color_palette())\n",
    "## take the average result obtained over all the segment of all datasets.\n",
    "trial_rinter = noise_data[2,:,np.where(metrics_name==name_index[0])[0]]\n",
    "\n",
    "sns.histplot(trial_rinter[0,:],color=next(palette))\n",
    "print(np.mean(trial_rinter[0,:]))\n",
    "print(np.std(trial_rinter[0,:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
