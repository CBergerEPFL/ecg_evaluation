{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using mit-bih-noise-stress-test-database, Test our models and index performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "import os\n",
    "import itertools\n",
    "import sys\n",
    "import xarray as xr\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "from operations.dataset_manager import get_path_petastorm_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_save_path = \"/workspaces/ecg_evaluation/results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['backward_pval_selection.sav', 'hjmi_selection.sav','L2_reg_logistic.sav']\n",
    "#model_name = ['backward_pval_selection.sav', 'hjmi_selection.sav',\"lgbm_prob.sav\", 'L2_reg_logistic.sav']\n",
    "#model_name = ['backward_pval_selection', 'hjmi_selection', 'L2_reg_logistic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_index = [\n",
    "        \"Corr_interlead\",\n",
    "        \"Corr_intralead\",\n",
    "        \"wPMF\",\n",
    "        \"SNRECG\",\n",
    "        \"HR\",\n",
    "        \"Flatline\",\n",
    "        \"TSD\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model on new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please note that you will have to get your dataset ready and your metrics already calculated using the command describe on the git repo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_path = \"/workspaces/ecg_evaluation/results/mit_bih_noise_test_metrics.nc\"\n",
    "metrics = xr.load_dataset(data_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check data metrics \n",
    "id_signals = metrics.id.values\n",
    "metrics_name = metrics.metric_name.values.tolist()\n",
    "values_metrics = metrics.quality_metrics.values\n",
    "signal = metrics.signal.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_containing_substring(the_list, substring):\n",
    "    list_index = []\n",
    "    for i, s in enumerate(the_list):\n",
    "        if substring in s:\n",
    "              list_index.append(i)\n",
    "    return list_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test each model performance for each noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will specifically focus on the noises signal. So, let's isolate them :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_noise_new = [\"em\",\"ma\",\"bw\"]\n",
    "list_noise_old = [\"oldem\",\"oldma\",\"oldbw\"]\n",
    "\n",
    "list_index_oldem = index_containing_substring(id_signals,list_noise_old[0])\n",
    "list_index_em = index_containing_substring(id_signals,list_noise_new[0])[len(list_index_oldem):]\n",
    "\n",
    "list_index_oldma = index_containing_substring(id_signals,list_noise_old[1])\n",
    "list_index_ma = index_containing_substring(id_signals,list_noise_new[1])[len(list_index_oldma):]\n",
    "\n",
    "list_index_oldbw = index_containing_substring(id_signals,list_noise_old[2])\n",
    "list_index_bw = index_containing_substring(id_signals,list_noise_new[2])[len(list_index_oldbw):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_index_noise = {\"em\" : list_index_em,\n",
    "                    \"ma\" : list_index_ma,\n",
    "                    \"bw\" : list_index_bw,\n",
    "                    \"oldem\" : list_index_oldem,\n",
    "                    \"oldma\" : list_index_oldma,\n",
    "                    \"oldbw\" : list_index_oldbw}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3 type of noise. We will reunite the old and new version\n",
    "noise_data = np.zeros([len(list_noise_new),len(list_index_bw)*2,values_metrics.shape[1],values_metrics.shape[-1]])\n",
    "\n",
    "for i in range(noise_data.shape[0]):\n",
    "    ind_new = dico_index_noise[list_noise_new[i]]\n",
    "    ind_old = dico_index_noise[list_noise_old[i]]\n",
    "    noise_data[i,:,:,:] = np.concatenate((values_metrics[ind_new,:,:],values_metrics[ind_old,:,:]),axis = 0)\n",
    "\n",
    "print(noise_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Small check concerning the values performance for each noise.\n",
    "plt.rcParams.update({\"font.size\": 20})\n",
    "plt.rcParams[\"legend.fontsize\"] = 20\n",
    "fig,axes = plt.subplots(2, 4, figsize=(20, 15),constrained_layout = True)\n",
    "fig.tight_layout(pad=5)\n",
    "fig.suptitle(f\"Histogram value for each type of noise\")\n",
    "fig.subplots_adjust(top=0.88)\n",
    "## take the average result obtained over all the segment of all datasets.\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(int(len(metrics_name)/2)):\n",
    "        palette = itertools.cycle(sns.color_palette())\n",
    "        for n in range(len(list_noise_new)):\n",
    "            trial_rinter = noise_data[n,:,:,i*(int(len(metrics_name)/2))+j]\n",
    "            axes[i,j].set_title(f\"{metrics_name[i*int(len(metrics_name)/2)+j]}\")\n",
    "            axes[i,j].grid()\n",
    "            sns.histplot(trial_rinter.reshape(-1),ax=axes[i,j],color=next(palette),label = list_noise_new[n],alpha = 0.5)\n",
    "            plt.setp(axes[i,j].get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "handles, labels = axes[0,0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper left',bbox_to_anchor=(-0.01, 1.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_index_label_mit_noise(ds_data,name_metrics,required_index):\n",
    "    np_metrics = ds_data\n",
    "    metrics_names = name_metrics\n",
    "    np_label = np.ones(np_metrics.shape[0]).astype(int)\n",
    "\n",
    "    df_X = pd.DataFrame(np_metrics, columns=metrics_names)\n",
    "    df_y = pd.DataFrame(np_label, columns=[\"y\"])\n",
    "\n",
    "    if required_index is not None:\n",
    "        df_X = df_X.loc[:, required_index]\n",
    "    else:\n",
    "        required_index = df_X.columns.tolist()\n",
    "\n",
    "    return df_X, df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SQA_method(data,name_metrics,feature_ex,model_path,model_name):\n",
    "\n",
    "    ##give the dataset with noise\n",
    "    X,_ = extract_index_label_mit_noise(data,name_metrics,feature_ex)\n",
    "    model = pkl.load(open(model_path,\"rb\"))\n",
    "    X = X.values\n",
    "    y_proba = model.predict_proba(X)\n",
    "    return y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_selection_features = [[\"Corr_interlead\", \"HR\", \"wPMF\", \"TSD\"],\n",
    "                           ['Corr_interlead', 'SNRECG', 'TSD', 'Corr_intralead'],\n",
    "                           #[\"Corr_interlead\",\"Corr_intralead\",\"wPMF\",\"SNRECG\",\"HR\",\"Flatline\",\"TSD\"],\n",
    "                           [\"Corr_interlead\", \"SNRECG\", \"HR\", \"Corr_intralead\", \"wPMF\"]]\n",
    "\n",
    "\n",
    "fig,axes = plt.subplots(1, 3, figsize=(20, 15),constrained_layout = True)\n",
    "fig.tight_layout(pad=5)\n",
    "fig.suptitle(f\"Histogram value for each noise type ('Unacceptable' class probability)\")\n",
    "fig.subplots_adjust(top=0.88)\n",
    "\n",
    "    \n",
    "for j in range(len(model_name)):\n",
    "    palette = itertools.cycle(sns.color_palette())\n",
    "    for n in range(len(list_noise_new)):\n",
    "        data = noise_data[n,:,:,:]\n",
    "        Y_P = np.array([])\n",
    "        for p in range(data.shape[0]):\n",
    "            Y_P =np.append(Y_P,SQA_method(data[p,:,:],metrics_name,list_selection_features[j],os.path.join(models_save_path,model_name[j]),model_name[j])[:,1])\n",
    "        axes[j].set_title(f\"{model_name[j].split('.')[0]}\")\n",
    "        sns.histplot(Y_P.reshape(-1),ax=axes[j],color=next(palette),label = list_noise_new[n],alpha = 0.5)\n",
    "        plt.setp(axes[j].get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='upper left',bbox_to_anchor=(-0.01, 1.01))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
