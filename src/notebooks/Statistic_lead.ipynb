{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from petastorm import make_reader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kurtosis,pearsonr\n",
    "from scipy.signal import periodogram\n",
    "from ecgdetectors import Detectors\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix,auc\n",
    "import sys\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import os\n",
    "import xarray as xr\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "from shared_utils.utils_data import format_data_to_xarray_2020,format_data_to_xarray,extract_index_label\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "path_formatted_glasgow = \"/workspaces/ecg_evaluation/data/20220902_data_physio_formatted_merged/merged/dataParquet\"\n",
    "path_petastorm = f\"file:///{path_formatted_glasgow}\"\n",
    "\n",
    "path_formated_cinc2011= \"/workspaces/ecg_evaluation/data/20221006_physio_quality/set-a/dataParquet\"\n",
    "path_petastorm_cinc2011 = f\"file:///{path_formated_cinc2011}\"\n",
    "\n",
    "save_path = \"/workspaces/ecg_evaluation/results\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load your dataset (including the one with the metrics calculated on Cinc2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load signals patient\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "os.path.join(save_path,\"\")\n",
    "if not \"ecg_data.nc\" in os.listdir(save_path):\n",
    "    ds_data_2011 = format_data_to_xarray(path_petastorm_cinc2011, save_path)\n",
    "else:\n",
    "    ds_data_2011 = xr.load_dataset(os.path.join(save_path,\"ecg_data.nc\"))\n",
    "\n",
    "save_path = \"/workspaces/ecg_evaluation/results\"\n",
    "os.path.join(save_path,\"\")\n",
    "if not \"quality_metrics.nc\" in os.listdir(save_path):\n",
    "    metrics_2011 = format_data_to_xarray(path_petastorm_cinc2011, save_path)\n",
    "else:\n",
    "    metrics_2011 = xr.load_dataset(os.path.join(save_path,\"quality_metrics.nc\"))\n",
    "\n",
    "save_path = \"/workspaces/ecg_evaluation/results\"\n",
    "os.path.join(save_path,\"\")\n",
    "if not \"ecg_data_2020.nc\" in os.listdir(save_path):\n",
    "    ds_data_2020 = format_data_to_xarray_2020(path_petastorm, save_path)\n",
    "else:\n",
    "    ds_data_2020 = xr.load_dataset(os.path.join(save_path,\"ecg_data_2020.nc\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function to use save model and get score for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_features  = [\"Corr_interlead\", \"Corr_intralead\", \"TSD\"]\n",
    "def SQA_method(data,feature_ex,model_path):\n",
    "    X,_ = extract_index_label(data,feature_ex)\n",
    "    model = pickle.load(open(model_path,\"rb\"))\n",
    "    X = X.values\n",
    "    y_proba = model.predict_proba(X)\n",
    "    return y_proba"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the dataset and get the labels. Divide into unacceptable and acceptable dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_filtered = ds_data_2011.where(ds_data_2011.data_quality != \"unlabeled\").dropna(dim = \"id\")\n",
    "signals = ds_filtered.signal.transpose(\"id\",\"lead_name\",\"time\")\n",
    "\n",
    "np_label = ds_filtered.data_quality.values\n",
    "unacceptable_data = signals[np_label==\"unacceptable\",:,:]\n",
    "acceptable_data = signals[np_label==\"acceptable\",:,:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get scores for both class on Cinc2011 using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(save_path,\"acceptable_score_2011.npy\")) and os.path.join(save_path,\"unacceptable_score_2011.npy\"):\n",
    "    acceptable_score = np.load(os.path.exists(os.path.join(save_path,\"acceptable_score_2011.npy\")),allow_pickle=True)\n",
    "    unacceptable_score = np.load(os.path.join(save_path,\"unacceptable_score_2011.npy\"),allow_pickle=True)\n",
    "else : \n",
    "    model_path= \"/workspaces/ecg_evaluation/results/hjmi_selection.sav\"\n",
    "    scores = SQA_method(metrics_2011,list_features,model_path=model_path)\n",
    "    unacceptable_score = scores[np_label==\"unacceptable\",:]\n",
    "    acceptable_score = scores[np_label==\"acceptable\",:]\n",
    "\n",
    "\n",
    "    np.save(os.path.join(save_path,\"acceptable_score_2011.npy\"),acceptable_score)\n",
    "    np.save(os.path.join(save_path,\"unacceptable_score_2011.npy\"),unacceptable_score)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptable_hist = pd.DataFrame(acceptable_score[:,0],columns = [\"0\"])\n",
    "unacceptable_hist = pd.DataFrame(unacceptable_score[:,1],columns = [\"1\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram for Cinc2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptable_set = acceptable_hist[\"0\"]\n",
    "unacceptable_set = unacceptable_hist[\"1\"]\n",
    "\n",
    "sn.histplot(acceptable_set, kde=True, color = 'darkblue',label = \"Acceptable\")\n",
    "plt.axvline(acceptable_set.mean(), color='b', linestyle='dashed', linewidth=1,label =\"mean value : {:.2f}\".format((acceptable_set.mean()).mean()))\n",
    "sn.histplot(unacceptable_set, kde=True, color = \"darkorange\",label = \"Unacceptable\")\n",
    "plt.axvline(unacceptable_set.mean(), color='orange', linestyle='dashed', linewidth=1,label =\"mean value : {:.2f}\".format((unacceptable_set.mean()).mean()))\n",
    "plt.legend(title = 'Quality')\n",
    "plt.title('Density Plot for each classes')\n",
    "plt.xlabel('SQA scores')\n",
    "plt.ylabel('Density')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get scores for both class on 2020 Challenge dataset using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comparison = ds_data_2020.signal.transpose(\"id\",\"lead_name\",\"time\")\n",
    "data_comparison = np.array(data_comparison)\n",
    "score_trial = np.empty([data_comparison.shape[0]*data_comparison.shape[1],2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(save_path,\"score_trial_1_2020.npy\")) and os.path.exists(os.path.join(save_path,\"score_trial_0_2020.npy\")):\n",
    "    score_trial_1 = np.load(os.path.join(save_path,\"score_trial_1_2020.npy\"),allow_pickle=True)\n",
    "    score_trial_0 = np.load(os.path.join(save_path,\"score_trial_0_2020.npy\"),allow_pickle=True)\n",
    "else : \n",
    "    score_trial_1 = np.array([])\n",
    "    score_trial_0 = np.array([])\n",
    "    for i in tqdm(range(data_comparison.shape[0]),desc =\"Calculating SQA score for each leads\",disable=not True):\n",
    "        signal_patient=np.array(data_comparison[i,:,:])\n",
    "        y_score = SQA_method.SQA_method_lead_score(signal_patient,500)\n",
    "        score_trial_1 = np.concatenate((score_trial_1,y_score[:,1]),axis = None)\n",
    "        score_trial_0 = np.concatenate((score_trial_0,y_score[:,0]),axis = None)\n",
    "    np.save(os.path.join(save_path,\"score_trial_1_2020.npy\"),score_trial_1)\n",
    "    np.save(os.path.join(save_path,\"score_trial_0_2020.npy\"),score_trial_0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram for the 2020 Challenge Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_hist_1 = pd.DataFrame(score_trial_1,columns = [\"1\"])\n",
    "signal_hist_0 = pd.DataFrame(score_trial_0,columns = [\"0\"])\n",
    "unacceptable_set = signal_hist_1[\"1\"]\n",
    "acceptable_set = signal_hist_0[\"0\"]\n",
    "\n",
    "sn.histplot(acceptable_set, kde=True,bins = 125, color = 'darkblue',label = \"acceptable\")\n",
    "plt.axvline(acceptable_set.mean(),color='k', linestyle='dashed', linewidth=1,label =\"mean value : {:.2f}\".format((acceptable_set.mean())))\n",
    "plt.axvline(np.quantile(acceptable_set,0.10),color='tab:pink', linestyle='dashed', linewidth=1,label =\"q10 acceptable : {:.2f}\".format((np.quantile(acceptable_set,0.10))))\n",
    "plt.axvline(np.quantile(acceptable_set,0.90),color='g', linestyle='dashed', linewidth=1,label =\"q90 acceptable : {:.2f}\".format((np.quantile(acceptable_set,0.90))))\n",
    "# sn.histplot(unacceptable_set, kde=True,bins  =125, color = \"darkorange\",label = \"Unacceptable\")\n",
    "# plt.axvline(unacceptable_set.mean(), color='c', linestyle='dashed', linewidth=1,label =\"mean value : {:.2f}\".format((unacceptable_set.mean()).mean()))\n",
    "# plt.axvline(np.quantile(unacceptable_set,0.10),color='r', linestyle='dashed', linewidth=1,label =\"q10 Unacceptable : {:.2f}\".format((np.quantile(unacceptable_set,0.10))))\n",
    "# plt.axvline(np.quantile(unacceptable_set,0.90),color='tab:brown', linestyle='dashed', linewidth=1,label =\"q90 Unacceptable : {:.2f}\".format((np.quantile(unacceptable_set,0.90))))\n",
    "plt.legend(title = 'Quality')\n",
    "plt.title('Density Plot for acceptable class with 2020 dataset')\n",
    "#plt.grid()\n",
    "plt.xlabel('SQA scores')\n",
    "plt.ylabel('Density')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "1e9b5c13aa136530306b9d0fda952fcd75969540fafdedb30f13be0697230024"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
